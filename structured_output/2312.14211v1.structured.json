{
  "filename": "2312.14211v1.pdf",
  "sections": [
    {
      "heading": "Introduction",
      "text": "NASA SciX 1 is a digital library and search engine that provides access to a vast collection of scientific literature covering fields such as Earth Science, Planetary Science, Heliophysics and Astrophysics (created by the Astrophysics Data System"
    },
    {
      "heading": "Retrieval Augmented Generation",
      "text": "One of the most common use cases of LLMs (popularized thanks to OpenAI's chatGPT) are chat sessions where the user provides instructions and the LLM generates a response back. If the user asks a question, the LLM will generate a response that is based on the data seeing during its training. For instance, if the user asks \"What is the age of the universe?\", most LLMs generate a response in line with \"The estimated age of the universe is 13.8 billion years old.\". However, LLMs will generate a response even if it was never trained with data that contained a response to the submitted questions. One recurrent question that we used in our experiments was \"What is iSpec?\". iSpec is a stellar spectroscopy tool\nAfter experimenting with multiple strategies, the prompt that worked best for most LLMs consisted of an initial system message where we provide a general contextual description of the role of the LLM (fundamentally, it is a helpful assistant interacting with a user), followed by the original user request and a set of interactions between the assistant (i.e., the LLM) and that user. These interactions were not really generated by the LLM, but we simulated them and feed them to the LLM. This way we can build an interaction that contains the textual snippets that the LLM can use to generate its final answer to the original user request. This is an example of the full prompt that we would provide to the LLM (in this case with just one snippet):\n<|system|> This is a system prompt, you are a helpful assistant. Please answer truthfully and logically. If you don't know or aren't sure about something, say so clearly.</s> <|user|>what is iSpec?</s> <|assistant|>Can you provide me with some snippets from the literature to answer?</s> <|user|>An increasing number of high-resolution stellar spectra is available today thanks to many past and ongoing extensive spectroscopic surveys. Consequently, the scientific community needs automatic...</s> <|assistant|>Ok, do you have anything else?</s> <|user|>This is all I found in the literature.</s> <|assistant|>Awesome! I am ready to respond in a concise way.</a> <|user|>Great! Go ahead!</s> <|assistant|> The LLM receives the above prompt, and it generates a response by predicting the next token until a certain stop token is emitted, which signals the end of the response. We tested this strategy with a long list of open-source LLMs from 7 to 13 billion parameters, and based on our very subjective impression, we found Zephyr"
    },
    {
      "heading": "Finding Relevant Snippets",
      "text": "The hardest part of implementing RAG is developing a system that allows to identify what are the most relevant text snippets to provide to the LLM. If the selected snippets contain misleading information or are not strictly related to the user's request, then the generated response is going to have a lower quality and it will not satisfy the user's needs. We implemented two different approaches to identify relevant text snippets."
    },
    {
      "heading": "The traditional NASA SciX search approach",
      "text": "NASA SciX search engine has been fine-tuned to serve the scientific community. It allows scientist to query the literature using extremely well curated metadata, textual matches, acronym expansion and synonyms (among other features). The corpus contains more than 20M entries, and it can be queried in an automatic way using an API. To take advantage of all this power, we decided to use a LLM to translate the user question into a request compatible with the NASA SciX search engine. This strategy allows us to retrieve the abstracts of the most relevant recent refereed articles.\nTo successfully translate user requests to valid NASA SciX request, we followed a similar strategy as described above. We provide the LLM with a system instruction that set the scene, describing the interaction between a user and an assistant that is an expert librarian who receive questions and response back with the best valid NASA SciX request to find answers. Then, we simulate a conversation where a user has already submitted multiple questions, and the assistant has built valid queries. Finally, we add the current user request and we let the LLM complete the dialog: <|system|> You are an expert librarian in creating structured queries to be submitted to NASA SciX. The system accepts queries using the Apache Solr search syntax. Available search fields include \"author\", \"abs\", and \"year\".</s> <|user|>What was written by Michael Kurtz in 2016?</s> <|assistant|>((author:\"Kurtz, Michael\") AND (year:2016))</s> <|user|>What are blackholes?</s> <|assistant|>(abs:(black holes))</s> <|user|>what is iSpec?</s> <|assistant|> However, despite the detailed instruction and the provided examples, the LLM may end up generating queries that are invalid or it would add superfluous text such as \"Sure! Here is your query:\". To avoid this problem, we imposed that the picked tokens should comply with a predefined grammar that is compatible with the NASA SciX service. Once the natural language question to NASA SciX query translation is completed, we used the NASA SciX API to issue a search and retrieving the abstracts from the top N results."
    },
    {
      "heading": "The modern Semantic Search approach",
      "text": "We went through all the indexed open access articles in the NASA SciX corpus, segmented the full-text content into small paragraphs, computed semantic vectors (i.e., embeddings) for each paragraph using the BAAI/bge-small-en model"
    },
    {
      "heading": "Conclusions",
      "text": "Implementing a internal web interface and API to easily interact with open-source LLMs has helped the NASA SciX team to better understand the limits and potential use cases of these models. In particular, we have seen how following the RAG approach offers substantial benefits such as being able to list the concrete sources uses to generate a response and reduce the number of hallucinations by only relying on abstracts. Additionally, we observed that the use of full-text snippets improves the overall quality of the generated responses, making them more detailed and specific.\nIt is important to highlight that the results presented here are part of an internal NASA SciX experiment aimed at exploring the use of LLMs within the project. The developed web interface and services are not intended to be deployed openly to the general public. We recognize that there are costs and risks associated to openly offering a service of this characteristics. For example, currently the model utilizes one GPU, and it can only answer one request at a time. Allowing multiple parallel requests would require having at our disposal a larger number of GPUs. However, this experiment has been key to explore how NASA SciX could better serve its users by relying on LLMs for tasks such as data enrichment, classification, and knowledge extraction."
    }
  ],
  "tei_figures": [],
  "tei_tables": [],
  "pdffigures2": []
}